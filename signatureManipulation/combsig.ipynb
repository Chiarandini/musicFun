{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AudioSegment class for processing audio and the\n",
    "# split_on_silence function for separating out silent chunks.\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.playback import play\n",
    "import numpy as np\n",
    "import pyrubberband as pyrb\n",
    "import signatureClass as signatureClass\n",
    "# Define a function to normalize a chunk to a target amplitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CombinedSignature:\n",
    "    \"\"\"Takes two signatures and combines them. There are various different methods of\n",
    "    combinations, and so there is a class to keep all ways of combining and tweaking of\n",
    "    two signatures.\n",
    "\n",
    "    Attributes:\n",
    "        signature1: 1st signature. Must be a wav file\n",
    "        signature2: 2nd signature. Must be a wav file\n",
    "        splits_signature_1: List containing the segments that the 1st signature was split into\n",
    "        splits_signature_2: List containing the segments that the 1st signature was split into\n",
    "        combined_signature: output of the combine function (change which method used to get different results)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, signature1, signature2):\n",
    "        if type(signature1) is str and type(signature2) is str:\n",
    "            print(\"entered str\")\n",
    "            try:\n",
    "                # stores signatures that need to be combined\n",
    "                self.signature_1 = AudioSegment.from_file(signature1)\n",
    "                self.signature_2 = AudioSegment.from_file(signature2)\n",
    "                if round(self.signature_1.duration_seconds) != round(self.signature_2.duration_seconds):\n",
    "                    raise AttributeError(\"Both audiofiles must have the same duration\")\n",
    "            except FileNotFoundError:\n",
    "                raise FileNotFoundError(\"File not Found\")\n",
    "        elif type(signature1) is signatureClass and type(signature2) is signatureClass:\n",
    "            print(\"entered Signature\")\n",
    "            # stores signatures that need to be combined\n",
    "            self.signature_1 = signature1.base_audio\n",
    "            self.signature_2 = signature2.base_audio\n",
    "        else:\n",
    "            raise TypeError('input type must both either be string (paths) of Signature objects')\n",
    "\n",
    "        # store the two signatures after the splitting method has been executed\n",
    "        self.splits_signature_1 = []\n",
    "        self.splits_signature_2 = []\n",
    "\n",
    "        # stores resulting combined signatture (i.e., the output of the program)\n",
    "        self.combined_signature = None\n",
    "\n",
    "    # maybe this: https://stackoverflow.com/questions/682504/what-is-a-clean-pythonic-way-to-implement-multiple-constructors\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "    def _match_target_amplitude(self, aChunk, target_dBFS):\n",
    "        ''' Normalize given audio chunk '''\n",
    "        change_in_dBFS = target_dBFS - aChunk.dBFS\n",
    "        return aChunk.apply_gain(change_in_dBFS)\n",
    "\n",
    "    def _split_method_1(self, audio, silence_len=10, silence_tresh=-56) -> list[AudioSegment]:\n",
    "        \"\"\"split the audio where there are silences\n",
    "\n",
    "        Returns:\n",
    "            list containing AudioSegment segments.\n",
    "        \"\"\"\n",
    "        return split_on_silence(\n",
    "            # Use the loaded audio.\n",
    "            audio,\n",
    "            # Specify that a silent chunk must be at least 2 seconds or 2000 ms long.\n",
    "            min_silence_len=silence_len,\n",
    "            # Consider a chunk silent if it's quieter than -16 dBFS.\n",
    "            # (You may want to adjust this parameter.)\n",
    "            silence_thresh=silence_tresh,\n",
    "            # keep as much silence as possible\n",
    "            keep_silence=500\n",
    "        )\n",
    "\n",
    "    def split(self, method=_split_method_1) -> None:\n",
    "        \"\"\"Splits signature_1 and signature_2 bassed off of the desired method\n",
    "           (default method provided)\n",
    "\n",
    "        Args:\n",
    "            method (func): the method of audio splitting\n",
    "        \"\"\"\n",
    "        self.splits_signature_1 = method(self, self.signature_1)\n",
    "        self.splits_signature_2 = method(self, self.signature_2)\n",
    "\n",
    "    def _audio_speed(self, audiosegment, speed=1.0):\n",
    "        y = np.array(audiosegment.get_array_of_samples())\n",
    "        if audiosegment.channels == 2:\n",
    "            y = y.reshape((-1, 2))\n",
    "\n",
    "        sample_rate = audiosegment.frame_rate\n",
    "        y_fast = pyrb.time_stretch(y, sample_rate, speed)\n",
    "\n",
    "        channels = 2 if (y_fast.ndim == 2 and y_fast.shape[1] == 2) else 1\n",
    "        y = np.int16(y_fast * 2 ** 15)\n",
    "\n",
    "        return AudioSegment(y.tobytes(), frame_rate=sample_rate, sample_width=2, channels=channels)\n",
    "\n",
    "    def _combine_method_1(self, split_1: list[AudioSegment], split_2: list[AudioSegment]):\n",
    "        \"\"\"Take two split signatures, and tries to choose the combination that is as\n",
    "        close as half as possible, then combine those, and normalize their length\n",
    "\n",
    "        Args:\n",
    "            split_1: 1st split audio segments\n",
    "            split_2: 2nd spit audio segments\n",
    "\n",
    "        TODO:\n",
    "            currently, if forward and backward tally are the same, the first is chosen\n",
    "            since it executes first. You may want slightly different behavior.\n",
    "        \"\"\"\n",
    "        # NOTE : These are for testing purposes (don't know how to mock objects in python yet)\n",
    "        # lengths_1 = [2, 2, 0.25, 4.75]\n",
    "        # lengths_2 = [2, 2, 2, 2, 2]\n",
    "        lengths_1 = [len(v) / 1000 for v in split_1]\n",
    "        lengths_2 = [len(v) / 1000 for v in split_2]\n",
    "\n",
    "        half = sum([len(v) / 1000 for v in split_2]) / 2\n",
    "\n",
    "        # Find what is the closest the segments gets to the half-way point\n",
    "        # NOTE: python doesn't have a do-while loop, so had to jank it\n",
    "        forward_tally_1 = 0\n",
    "        forward_prev_1 = 0\n",
    "        forward_iter_1 = 0\n",
    "        while True:\n",
    "            forward_prev_1 = forward_tally_1\n",
    "            forward_tally_1 += lengths_1[forward_iter_1]\n",
    "            forward_iter_1 += 1\n",
    "            if forward_tally_1 >= half:\n",
    "                break\n",
    "\n",
    "        forward_tally_2 = 0\n",
    "        forward_prev_2 = 0\n",
    "        forward_iter_2 = 0\n",
    "        while True:\n",
    "            forward_prev_2 = forward_tally_2\n",
    "            forward_tally_2 += lengths_2[forward_iter_2]\n",
    "            forward_iter_2 += 1\n",
    "            if forward_tally_2 >= half:\n",
    "                break\n",
    "\n",
    "        backward_tally_1 = 0\n",
    "        backward_prev_1 = 0\n",
    "        backward_iter_1 = 1\n",
    "        while True:\n",
    "            backward_prev_1 = backward_tally_1\n",
    "            backward_tally_1 += lengths_1[-backward_iter_1]\n",
    "            backward_iter_1 += 1\n",
    "            if backward_tally_1 >= half:\n",
    "                break\n",
    "\n",
    "        backward_tally_2 = 0\n",
    "        backward_prev_2 = 0\n",
    "        backward_iter_2 = 1\n",
    "        while True:\n",
    "            backward_prev_2 = backward_tally_2\n",
    "            backward_tally_2 += lengths_2[-backward_iter_2]\n",
    "            backward_iter_2 += 1\n",
    "            if backward_tally_2 >= half:\n",
    "                break\n",
    "\n",
    "        # conditionals for finding the best splitting\n",
    "        all_options_1 = [forward_tally_1, forward_prev_1, backward_tally_1, backward_prev_1]\n",
    "        min_val_1 = min(all_options_1, key=lambda x: abs(x - half))\n",
    "\n",
    "        if min_val_1 == forward_tally_1:\n",
    "            part_1 = sum(split_1[0:forward_iter_1])\n",
    "        elif min_val_1 == forward_prev_1:\n",
    "            part_1 = sum(split_1[0:forward_iter_1 - 1])\n",
    "        elif min_val_1 == backward_tally_1:\n",
    "            part_1 = sum(split_1[-backward_iter_1 + 1:])\n",
    "        else:\n",
    "            part_1 = sum(split_1[-backward_iter_1 + 2:])\n",
    "\n",
    "        all_options_2 = [forward_tally_2, forward_prev_2, backward_tally_2, backward_prev_2]\n",
    "        min_val_2 = min(all_options_2, key=lambda x: abs(x - half))\n",
    "\n",
    "        if min_val_2 == forward_tally_2:\n",
    "            part_2 = sum(split_2[0:forward_iter_2])\n",
    "        elif min_val_2 == forward_prev_2:\n",
    "            part_2 = sum(split_2[0:forward_iter_2 - 1])\n",
    "        elif min_val_2 == backward_tally_2:\n",
    "            part_2 = sum(split_2[-backward_iter_2 + 1:])\n",
    "        else:\n",
    "            part_2 = sum(split_2[-backward_iter_2 + 2:])\n",
    "\n",
    "        # TODO: normalize the lengths so that they are each half length\n",
    "        # normalized_1 = self._audio_speed(part_1, part_1.duration_seconds / half)\n",
    "        # normalized_2 = self._audio_speed(part_2, part_2.duration_seconds / half)\n",
    "\n",
    "        self.combined_signature = part_1 + part_2\n",
    "        # self.combined_signature = normalized_1 + normalized_2\n",
    "\n",
    "        # TODO: Combine normalized_part_1 and normalized_part_2\n",
    "    def _combine_method_2(self, split_1: list[AudioSegment], split_2: list[AudioSegment]):\n",
    "        \"\"\"Take two split signatures, take the longest ones, and combine them.\n",
    "\n",
    "        Args:\n",
    "            split_1: 1st split audio segments\n",
    "            split_2: 2nd spit audio segments\n",
    "        \"\"\"\n",
    "        longest_clip_1 = max(split_1, key=len)\n",
    "        longest_clip_2 = max(split_2, key=len)\n",
    "\n",
    "        self.combined_signature = longest_clip_1 + longest_clip_2\n",
    "\n",
    "    def combine(self, method=_combine_method_1):\n",
    "        method(self, self.splits_signature_1, self.splits_signature_2)\n",
    "\n",
    "    def execute(self):\n",
    "        self.split()\n",
    "        self.combine()\n",
    "\n",
    "    def save_splits(self, path: str, chunks):\n",
    "\n",
    "        # Process each chunk with your parameters\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Create a silence chunk that's 0.5 seconds (or 500 ms) long for padding.\n",
    "            # silence_chunk = AudioSegment.silent(duration=500)\n",
    "\n",
    "            # Add the padding chunk to beginning and end of the entire chunk.\n",
    "            # audio_chunk = silence_chunk + chunk + silence_chunk\n",
    "\n",
    "            # Normalize the entire chunk.\n",
    "            normalized_chunk = self._match_target_amplitude(chunk, -20.0)\n",
    "\n",
    "            # Export the audio chunk with new bitrate.\n",
    "            print(\"Exporting chunk{0}.mp3.\".format(i))\n",
    "            normalized_chunk.export(\n",
    "                path + \"/chunk{0}.mp3\".format(i),\n",
    "                bitrate=\"192k\",\n",
    "                format=\"mp3\"\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/q3/tk2r4g4s7q99flpkyzlkrv2r0000gn/T/tmpdx3y0_tk.wav':\n",
      "  Duration: 00:00:10.00, bitrate: 705 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "   9.94 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/q3/tk2r4g4s7q99flpkyzlkrv2r0000gn/T/tmpx37a4ibq.wav':\n",
      "  Duration: 00:00:00.50, bitrate: 177 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 11025 Hz, 1 channels, s16, 176 kb/s\n",
      "   0.32 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/q3/tk2r4g4s7q99flpkyzlkrv2r0000gn/T/tmplwed_w2b.wav':\n",
      "  Duration: 00:00:10.00, bitrate: 705 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "   9.91 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/q3/tk2r4g4s7q99flpkyzlkrv2r0000gn/T/tmpftecmdpe.wav':\n",
      "  Duration: 00:00:00.90, bitrate: 176 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 11025 Hz, 1 channels, s16, 176 kb/s\n",
      "   0.70 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/q3/tk2r4g4s7q99flpkyzlkrv2r0000gn/T/tmpxqhmkscu.wav':\n",
      "  Duration: 00:00:09.33, bitrate: 705 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "   9.18 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   9.26 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    }
   ],
   "source": [
    "number1, number2 = '001', '002'\n",
    "# number1, number2 = '033', '020'\n",
    "# number1, number2 = '034', '050'\n",
    "sig1, sig2 = '../signatures/Signature-4_' + number1 + '.mp3', '../signatures/Signature-4_' + number2 + '.mp3'\n",
    "test = CombinedSignature(sig1, sig2)\n",
    "test.execute()\n",
    "\n",
    "audio1, audio2 = AudioSegment.from_file(sig1), AudioSegment.from_file(sig2)\n",
    "play(audio1)\n",
    "play(AudioSegment.silent(500))\n",
    "play(audio2)\n",
    "play(AudioSegment.silent(900))\n",
    "play(test.combined_signature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claryenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
